---
title: "assess_spat_auto"
output: html_document
---

Assessing spatial autocorrelation in the matched ecomon-copernicus dataset. 

```{r}
source("../../setup.R")
suppressPackageStartupMessages({
  library(ape) 
  library(nlme)
  library(viridis)
  })

root <- "/mnt/ecocast/projectdata/students/ojohnson/copernicus/model_data"
mec <- readr::read_csv(file.path(root, "mec_brickman_bathy.csv.gz"),
                       col_types = readr::cols()) |>
  mutate(patch = corrected_CIV_CVI_m2 >= 30000)
nrow(mec)

plot_gen(mec, "corrected_CIV_CVI_m2", "Cursory overview", log_col = TRUE)
```

## Spatial Autocorrelation

First, we can examine spatial autocorrelation for each variable.

https://github.com/mcooper/moranfast has a function that functions in a memory-efficient
fashion for larger datasets, but its calculation methods are slightly different.

```{r}
# Creating inverted distance matrix
mec_dists_inverted <- 1/(as.matrix(dist(cbind(mec$longitude, mec$latitude))) + .001)
diag(mec_dists_inverted) <- 0

covariates <- var_abb()[colnames(mec)] |> compact()

# Calculating Moran's I
morans_table <- covariates |> 
  imap(function(name, var) {
  moran <- Moran.I(pull(mec, var), mec_dists_inverted)
  c("Variable" = name, "Abb" = var, unlist(moran))
}) |> bind_rows() 

morans_table <- morans_table |>
  mutate(across(observed:p.value, as.numeric))

p <- ggplot(morans_table, aes(x = Variable, y = observed)) + 
  geom_bar(stat = 'identity', fill = "dodgerblue4") +
  guides(x =  guide_axis(angle = 45)) +
  labs(y = "Observed Moran's I", title = "Spatial autocorrelation of covariates") +
  theme_bw()

#save_pdf_ecocast(p, "spatial_autocorrelation_covariates", root)

p
```

We can also calculate autocorrelation for patch as done in Johnson et al. 2025. Thankfully this is quite low, even lower than prior autocorrelation of .108 for AZMP/Ecomon.

```{r}
Moran.I(pull(mec, "patch") |> as.numeric(), mec_dists_inverted)
```
### Temporal Autocorrelation

This requires binning our data into chunks. We *could* use [tidySDM](https://evolecolgroup.github.io/tidysdm/index.html) for this but we're
just gonna do it manually using dplyr. While the resolution of the final prediction is 1/12°, we're going to bin the data into smaller chunks (1/4°) to increase information per cell.

```{r}
c_num <- 4 # Inverse of chunk size (1/4°)
get_chunk <- function(coord) {
  # paste0(round(lat * 12), ".", round(lon * 12))
  round(coord * c_num)
}

mec_chunked <- mec |>
  mutate(across(c(latitude, longitude), get_chunk), 
         patch = as.numeric(patch),
         month_numeric = 
           round(as.numeric(date - as.Date("1990-01-01"))/(365.25/12))) |>
  group_by(latitude, longitude, month_numeric) |>
  # For each date, retrieve number of observations and means of observed values
  summarize(n = n(), across(bottomT:patch, mean), .groups = "drop_last")

#' Assesses temporal autocorrelation based on value and irregularly spaced
#' numeric months
#' This code could be optimized by accepting all variable vectors at once, 
#' so it can construct the dataframe just the one time and return a named list
assess_autocorr_gls <- function(var_vec, mon_vec) {
  df <- data.frame(value = var_vec, date_mons = mon_vec)

  if (nrow(df) < 8) return(NA)  # avoid fitting on tiny groups

  gls_model <- try(gls(value ~ 1,
                       correlation = corCAR1(form = ~ date_mons),
                       data = df), silent = TRUE)
  if (inherits(gls_model, "try-error")) return(NA)

  coef(gls_model$modelStruct$corStruct, unconstrained = FALSE)[[1]] # Phi
}

# Retrieving autocorrelation for each latitude/longitude group
mec_autocorr_summarized <- mec_chunked |>
  summarize(n = sum(n), 
            across(bottomT:zos, ~assess_autocorr_gls(.x, month_numeric)), 
            .groups = "drop")

head(mec_autocorr_summarized)
```

Let's make some plots!

```{r}
plot_base_autocorr <- function(data, variable, title) {
    ggplot(data, 
           aes(x = longitude/c_num, y = latitude/c_num, fill = get(variable))) +
    geom_tile() +
    geom_polygon(data = ggplot2::map_data("world"), 
                 aes(long, lat, group = group),
                 fill = "lightgray", col = "gray") +
    coord_quickmap(xlim = c(-76, -65), ylim = c(36, 45), expand = TRUE) +
    labs(x = "Longitude", y = "Latitude", fill = variable, title = title) +
    theme_bw() +
    scale_fill_viridis()
}

mec_autocorr_summarized |>
  plot_base_autocorr("n", "Number of Records per cell")

mec_autocorr_summarized |>
  pivot_longer(cols = bottomT:zos) |>
  plot_base_autocorr("value", "Temporal Autocorrelation") +
  facet_wrap(~ name) +
  theme_void()
```

Temporal autocorrelation (on a month-to-month basis) seems to be fairly high for bottom temperature and salinity. 
